using Test
using TumorGrowth
import StableRNGs.StableRNG
using IterationControl
import Lux
using Plots

function normalized_absolute_difference(yhat, y)
    scale = abs(y)
    abs(yhat - y)/scale
end
mape(yhat, y) = sum(broadcast(normalized_absolute_difference, yhat, y))/length(y)

@testset "CalibrationProblem" begin

    # test calibration using bertalanffy2:
    tol = 0.3
    rng = StableRNG(123)
    p_true = (v0 = 0.013, v∞ = 0.000725, ω = 0.077, λ = 0.2, γ = 1.05)
    times = range(0.1, stop=47.0, length=5) .* (1 .+ .05*rand(rng, 5))
    volumes_true = bertalanffy2(times, p_true)
    problem = CalibrationProblem(
        times,
        volumes_true,
        bertalanffy2;
        frozen = (; λ=p_true[4]),
        learning_rate=0.001,
        penalty=0.01,
        reltol=1e-6,
    )
    l(p) = mape(collect(p), collect(p_true))
    # To diagnose issues, uncomment next 3 commented lines below and do `using Plots`.
    outcomes = solve!(
        problem,
        Step(1),
        InvalidValue(),
        # TimeLimit(5/60),
        NumberLimit(450),
        Callback(problem -> l(solution(problem)) < tol; stop_if_true=true),
        # Callback(problem -> print("\r", pretty(solution(problem)))),
        # Callback(problem->(plot(problem); gui())),
    )
    # check that stop triggered by callback:
    @test outcomes[4][2].done
    @test l(solution(problem)) < tol
    bertalanffy2_loss = loss(problem)
    # smoke test for plots:
    plot(problem)

    # try a neural2 network on the same training data (generated by `bertalanffy2` model) (need
    # 1/10th the learning rate):
    network = Lux.Chain(
        Lux.Dense(2, 5, Lux.tanh, init_weight=Lux.zeros64),
        Lux.Dense(5, 2),
    )
    rng = StableRNG(123)
    model = neural2(rng, network)
    problem = CalibrationProblem(
        times,
        volumes_true,
        model;
        frozen = (; v∞=nothing),
        learning_rate=0.0001,
        half_life=48.0,
    )

    # scatter(times, volumes_true)
    outcomes = solve!(
        problem,
        Step(1),
        InvalidValue(),
        # TimeLimit(5/60),
        NumberLimit(800),
        Threshold(bertalanffy2_loss),
        # Callback(problem -> print("\r", pretty(solution(problem)))),
        # IterationControl.skip(
        #    Callback(problem->(plot(problem); gui())),
        #    predicate=20,),
    )
    # check that stop triggered by threshold:
    @test outcomes[4][2].done
    @test loss(problem) < bertalanffy2_loss

    # check that `v∞` was indeed frozen:
    @test solution(problem).v∞ == TumorGrowth.guess_parameters(times, volumes_true, model).v∞
end

true
